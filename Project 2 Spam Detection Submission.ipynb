{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "PDS Project 2: Spam Detection <br>\n",
    "Connor Moore | Gaury Nagaraju <br>\n",
    "Date: 09 May, 2016\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=1> <li><b> Problem & Domain: </b> </li> </ol>\n",
    "- Phising is one of the leading sources of viruses\n",
    "- Spam filtering is one of the primary ways to fight spam and viruses sent via email.\n",
    "\n",
    "<ol start=2> <li><b> Dataset: </b> </li> </ol>\n",
    "- Sources Explored for Datasets: South African Hindawai Journal Research, Phishtank, Enron datasets\n",
    "- Source Selected: CSMining Group http://csmining.org/index.php/spam-email-datasets-.html\n",
    "- Dataset:\n",
    "Training Emails: Labeled emails with 4327 messages in .eml format (2949 non-spam, 1378 spam)\n",
    "Testing Email: Unlabeled Emails - 4292 messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=3>\n",
    "    <li> <b> Data Sanitization </b> </li> <br>\n",
    "    <ul>\n",
    "        <li> Detect Character Set of Email and extract payload. </li>\n",
    "        <li> Loop through all emails: get isSpam Label, payload and store in a Dictionary. Ignore email if character set is not recognizable. </li>\n",
    "        <li> Pickle Dictionary </li>\n",
    "    </ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import email.parser \n",
    "import os, sys, stat\n",
    "import chardet\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExtractSubPayload (filename):\n",
    "    ''' Extract the subject and payload from the .eml file.\n",
    "\n",
    "    '''\n",
    "    if not os.path.exists(filename): # dest path doesnot exist\n",
    "        print(\"ERROR: input file does not exist:\", filename)\n",
    "        os.exit(1)\n",
    "\n",
    "    f = open(filename)\n",
    "\n",
    "    msg = email.message_from_file(f)\n",
    "\n",
    "    # Subject, to and from fields\n",
    "    sub = msg.get('subject')\n",
    "    sub = str(sub)\n",
    "    to = str(msg.get('to'))\n",
    "    fr = str(msg.get('from'))\n",
    "\n",
    "    # get body of message\n",
    "    payload = msg.get_payload()\n",
    "    \n",
    "    # Beautiful Soup\n",
    "    soup = BeautifulSoup(payload, 'html.parser')\n",
    "    payload = soup.get_text()\n",
    "    \n",
    "    if type(payload) == type(list()) :\n",
    "        payload = payload[0] # only use the first part of payload\n",
    "    if type(payload) != type('') :\n",
    "        # payload = str(payload)\n",
    "        payload = payload.encode('ascii', 'replace')\n",
    "    \n",
    "    # Charset of payload\n",
    "    charset = chardet.detect(payload)['encoding']\n",
    "\n",
    "    return {\"charset\": charset, \"payload\": payload}\n",
    "    close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDict = {}\n",
    "\n",
    "with open(\"SPAMTrain.label\") as f:\n",
    "    for line in f:\n",
    "#         print(line[2:])\n",
    "        isSpam = int(line[0])\n",
    "        filename = line[2:]\n",
    "        trainDict[filename.strip()] = isSpam\n",
    "        \n",
    "# print trainDict\n",
    "x = 0\n",
    "deleteKeys = []\n",
    "for mail in trainDict:\n",
    "    try:\n",
    "        res = ExtractSubPayload(\"TRAINING/\"+mail)\n",
    "    except:\n",
    "        deleteKeys += [mail]\n",
    "        continue\n",
    "#     print res['filename']\n",
    "#     print mail\n",
    "    res[\"isSpam\"] = trainDict[mail]\n",
    "    trainDict[mail] = res\n",
    "    if(x %1000 == 0):\n",
    "        print x\n",
    "    x+=1\n",
    "\n",
    "# delete keys, i.e. emails whose charset were not recognizable\n",
    "for d in deleteKeys:\n",
    "    trainDict.pop(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"emailData.pickle\", \"w\") as f:\n",
    "    pickle.dump(trainDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"emailData.pickle\", \"rb\") as f:\n",
    "    trainDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(trainDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optional: View formatted payload of each email\n",
    "for mail in trainDict:\n",
    "    print trainDict[mail]['payload']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=4>\n",
    "<li> <b> Feature Extraction </b> </li>\n",
    "</ol><br>\n",
    "Significance of Metrics: <br>\n",
    "<li> Recall: positive identification of spam from all of test data. <i> Note: Recall = 1-FP (False Positive Rate) </i> </li>\n",
    "<li> Precision: positive identification of spam from those identified as spam </li>\n",
    "<li> Accuracy: model accuracy </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extractor 1: <br>\n",
    "CountVectorizer: counts word occurrence in each email <br>\n",
    "TreebankWordTokenizer: nltk (natural language processing package in python)'s tokenizer which does a good job of tokenizing words in a string based on natural speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(tokenizer=TreebankWordTokenizer().tokenize, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = list()\n",
    "labels = list()\n",
    "\n",
    "for k in trainDict:\n",
    "    # get body\n",
    "    body = trainDict[k]['payload']\n",
    "    charset = trainDict[k]['charset']\n",
    "    isSpam = trainDict[k]['isSpam']\n",
    "    if charset == None:\n",
    "        charset = 'ascii'\n",
    "    bodyStr = body.decode(charset, errors='replace').encode('utf-8', 'replace')\n",
    "    \n",
    "    # append to l and label\n",
    "    l.append(bodyStr)\n",
    "    labels.append(isSpam)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vec.fit_transform(l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=1000, random_state=42)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extractor 2: with Content Filter <br>\n",
    "CountVectorizer: counts word occurrence in each email <br>\n",
    "Spacy Tokenizer: Does a better job of tokenizing words taking into consideration digits, punctuation marks, urls and various other factors <br>\n",
    "SpamAssassin's list of words to be excluded: http://wiki.apache.org/spamassassin/BayesStopList <br>\n",
    "Words less than 3 character long are ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source: http://wiki.apache.org/spamassassin/BayesStopList\n",
    "# SpamAssasin: word length < 3 excluded and words in given list excluded\n",
    "exclusive_list = ['able', 'all', 'already', 'and', 'any', 'are', 'because','both', 'can', 'come', 'each', 'email', 'even', 'few', 'first', 'for', 'from', 'give', 'has', 'have', 'http', 'information', 'into', \"it's\", 'just', 'know','like', 'long', 'look', 'made', 'mail', 'mailing', 'mailto', 'make', 'many','more', 'most', 'much', 'need', 'not', 'now', 'number', 'off', 'one', 'only', 'out', 'own', 'people', 'place', 'right', 'same', 'see', 'such', 'that', 'the', 'this', 'through', 'time', 'using', 'web', 'where', 'why', 'with', 'without', 'work', 'world', 'year', 'years', 'you', 'your', \"you're\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ignore_word(word):\n",
    "    # ignore digits, punctuation marks, spaces, stop words, new line chars\n",
    "    if word.is_digit or word.is_punct or word.is_space or word.is_stop or str(word)=='\\n' or word.like_num:\n",
    "        return True\n",
    "    elif word in exclusive_list:\n",
    "        return True\n",
    "    elif len(str(word)) < 3:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = list()\n",
    "labels = list()\n",
    "\n",
    "for k in trainDict:\n",
    "    # get body\n",
    "    body = trainDict[k]['payload']\n",
    "    charset = trainDict[k]['charset']\n",
    "    isSpam = trainDict[k]['isSpam']\n",
    "    if charset == None:\n",
    "        charset = 'ascii'\n",
    "    u = unicode(body, charset)\n",
    "    try:\n",
    "        # Tokenize using Spacy\n",
    "        words = en_nlp(u)\n",
    "        # Get relevant tokens\n",
    "        relevant_words = ''\n",
    "        for word in words:\n",
    "            if ignore_word(word):\n",
    "                continue\n",
    "            # consider words that contain alphabets or look like urls\n",
    "            elif word.is_alpha or word.like_url:\n",
    "                relevant_words+= str(word) + ' '\n",
    "        # append to list and labels\n",
    "        l.append(relevant_words)\n",
    "        labels.append(isSpam)\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vec.fit_transform(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=1000, random_state=42)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extractor 3: with ngrams range 1-3 <br>\n",
    "CountVectorizer ngrams: counts word occurrence in each email. Analyze groups of words. <br>\n",
    "Spacy Tokenizer: Does a better job of tokenizing words taking into consideration digits, punctuation marks, urls and various other factors <br>\n",
    "SpamAssassin's list of words to be excluded: http://wiki.apache.org/spamassassin/BayesStopList <br>\n",
    "Words less than 3 character long are ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,3), min_df=1, stop_words='english')\n",
    "X = vectorizer.fit_transform(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=1000, random_state=42)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extractor 4: with content filter and TfidfVectorizer <br>\n",
    "TfidfVectorizer: calculates term frequency, i.e. word count and weights it based on length of document. If term appears in too mnay documents, the term is ignored. <br>\n",
    "Spacy Tokenizer: Does a better job of tokenizing words taking into consideration digits, punctuation marks, urls and various other factors <br>\n",
    "SpamAssassin's list of words to be excluded: http://wiki.apache.org/spamassassin/BayesStopList <br>\n",
    "Words less than 3 character long are ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=1000, random_state=42)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extractor 5: with content filter <br>\n",
    "CountVectorizer: calculates word occurrences in email <br>\n",
    "Spacy Tokenizer Lemma: Get the lemma/ root for each word in the email and group different versions of the words into the lemma count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = list()\n",
    "labels = list()\n",
    "\n",
    "for k in trainDict:\n",
    "    # get body\n",
    "    body = trainDict[k]['payload']\n",
    "    charset = trainDict[k]['charset']\n",
    "    isSpam = trainDict[k]['isSpam']\n",
    "    if charset == None:\n",
    "        charset = 'ascii'\n",
    "    u = unicode(body, charset)\n",
    "    try:\n",
    "        # Tokenize using Spacy\n",
    "        words = en_nlp(u)\n",
    "        # Get relevant tokens\n",
    "        relevant_words = ''\n",
    "        for word in words:\n",
    "            # ignore digits, punctuation marks, spaces, stop words, new line chars\n",
    "            if word.is_digit or word.is_punct or word.is_space or word.is_stop or str(word)=='\\n' or word.like_num:\n",
    "                continue\n",
    "            # consider words that contain alphabets or look like urls\n",
    "            elif word.is_alpha or word.like_url:\n",
    "                # use lemma of word\n",
    "                relevant_words+= str(word.lemma_) + ' '\n",
    "        # append to list and labels\n",
    "        l.append(relevant_words)\n",
    "        labels.append(isSpam)\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=1000, random_state=42)\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=5>\n",
    "<li> <b> Feature Selection </b> </li>\n",
    "</ol>\n",
    "Select most relevant features given all the emails rather than considering counts of every word. <br>\n",
    "Tools Used: <br>\n",
    "ExtraTressClassifier: identifies important features from features found using CountVectorizer and returns a 0,1 np array. <br>\n",
    "SelectFromModel: Applies the result of ExtraTreesClassifier to our data to get value for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = list()\n",
    "labels = list()\n",
    "\n",
    "for k in trainDict:\n",
    "    # get body\n",
    "    body = trainDict[k]['payload']\n",
    "    charset = trainDict[k]['charset']\n",
    "    isSpam = trainDict[k]['isSpam']\n",
    "    if charset == None:\n",
    "        charset = 'ascii'\n",
    "    u = unicode(body, charset)\n",
    "    try:\n",
    "        # Tokenize using Spacy\n",
    "        words = en_nlp(u)\n",
    "        # Get relevant tokens\n",
    "        relevant_words = ''\n",
    "        for word in words:\n",
    "            if word.is_digit or word.is_punct or word.is_space or word.is_stop or str(word)=='\\n' or word.like_num:\n",
    "                continue\n",
    "            # consider words that contain alphabets or look like urls\n",
    "            elif word.is_alpha or word.like_url:\n",
    "                relevant_words+= str(word) + ' '\n",
    "        # append to list and labels\n",
    "        l.append(relevant_words)\n",
    "        labels.append(isSpam)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,3), min_df = 1, stop_words = 'english')\n",
    "X = vectorizer.fit_transform(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier()\n",
    "clf.fit(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(clf, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optional: Compare shape of X and X_new to see reduction in total number of features\n",
    "print X.shape\n",
    "print X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, labels, test_size=1000, random_state=42)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import  metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "# summarize the fit of the model\n",
    "\n",
    "print(metrics.accuracy_score(expected, predicted))\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=6>\n",
    "<li> <b> Spam Assassin </b> </li>\n",
    "</ol>\n",
    "We wrote a script that will give us the spam score for every email by making a request to the SpamAssassin server. Score > 5 is considered as spam. <br>\n",
    "The result output is a tuple with Spam Assassin's classification of the email and our label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "# our custom fork of the spamcheck\n",
    "cwd = os.getcwd()\n",
    "sys.path.append(cwd + 'SpamAss/spamcheck-python')\n",
    "import spamcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../cleanEmailData.pickle\") as f:\n",
    "    emailData = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For Testing Purposes: Try one clean email (without any new line or \\r characters)\n",
    "x = emailData[0][0].replace('\\n', ' ').replace('\\r', ' ')\n",
    "spamcheck.check(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "res = []\n",
    "for i in emailData:\n",
    "    filteredPayload = i[0].replace('\\n', ' ').replace('\\r', ' ')\n",
    "    isSpam = False\n",
    "    try:\n",
    "        if spamcheck.check(filteredPayload)['score'] > 5:\n",
    "            isSpam = True\n",
    "    except:\n",
    "        continue\n",
    "    res.append((isSpam, i[1]))\n",
    "    if i == 100:\n",
    "        break\n",
    "    x+=1\n",
    "    if (x % 50 == 0):\n",
    "        print x\n",
    "\n",
    "# The result is a tuple (SpamAssassin's classification of email as spam or not, our label of spam or not)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"spamAssassinData.pickle\", \"w\") as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"spamAssassinData.pickle\", \"rb\") as f:\n",
    "    res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=7>\n",
    "<li> <b> Understanding Model Results </b> </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While comparing different models, we should look at the recall and precision rates since they reveal our ability to classify an email as spam and the false positive rate. <br><br>\n",
    "The top 3 models with respect to these factors are: <br>\n",
    "1. CountVectorizer with content filters (Spacy Tokenizer, spam assassin exclusive word list) and ngrams. The model was 96.5% accurate. Recall and precision for spam were 0.95 and 0.94 respectively. <br>\n",
    "2. CountVectorizer with ngrams and feature selector (treeClassifier and selectFromModel that select most important features). The model was 95.7% accurate. Recall and precision for spam were 0.96 and 0.9 respectively.  <br>\n",
    "3. CountVectorizer without content filters or feature selectors.  The model was 95.8% accurate. Recall and precision for spam were 0.9 and 0.96 respectively. <br>\n",
    "<br>\n",
    "\n",
    "These metrics are very comparable to those of popular models such as the Enhanced Naive Bayes classifier by Paul Graham and Spam Assassin. Paul Graham has a catch rate of about 99.5% while our recall is around 95%.<br>\n",
    "However, our model has a higher false positive rate of around 6% in comparison to Paul Graham's 0.05% Some of the reasons include: <br>\n",
    "1. Message Headers: The email dataset we used didn't all have headers consistently and were often in various formats. So, we discarded all message headers but they definitely have a huge impact on classification, as mentioned by Paul Graham as well.\n",
    "2. Data Sanitization: Each email was in a different format; text, email reply threads, html, newsletter format. So, having a technique that would standardize the format may affect results since words associated with the format were included in the word counts. \n",
    "<br>\n",
    "Finally, a lot of email classifiers get to 95% accuracy and about 5% false positive rate. However, identifying features and content filters that decrease that 5% is the current challenge and a very dynamic problem since spammers constantly find ways to beat the algorithm. <br>\n",
    "\n",
    "As opposed to our hypothesis, models that used tfidf vectorizer and lemmas decreased performance because information is lost. In the tfidf vectorizer, ignoring words that appear in too many emails or weighting them based on the length of the email is not useful. Words are spammy regardless of their count or length of email they appear in. Similarly, using the lemma of each word results in loss of information about mis-spelt words or variations of words that occur in spam vs ham emails. <br>\n",
    "\n",
    "Some features that we plan to consider in the future are length of email, header information, subject of message, header information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=8>\n",
    "<li> <b> Conclusion and Future Actionable Steps </b> </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving ahead, we can \n",
    "1. Use better data sanitation techniques and maybe cluster emails into groups such as reply threads, newsletters, html structure, text.\n",
    "2. Find a way to extract message headers for all emails\n",
    "3. Clever feature engineering: Identify significant features apart from words in the email such as length of email, time it was sent, number of links in the email.\n",
    "4. Look into gmail filters such as degree of links between sender and receiver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=9>\n",
    "<li> <b> Appendix </b> </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting Observations we made while analyzng words present in the email\n",
    "<br>Appendix 1: Word Count Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spacy english module\n",
    "import spacy\n",
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create word count dictionary\n",
    "wordDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addToDict(word, isSpam):\n",
    "    # ignore some words\n",
    "    if word.is_digit or word.is_punct or word.is_space or word.is_stop:\n",
    "        return\n",
    "    # if every char in word is alphabet\n",
    "    elif word.is_alpha:\n",
    "        word = word.orth_[:].encode('ascii')\n",
    "        # else add to dict\n",
    "        if word.lower() in wordDict:\n",
    "            # index 0: spam\n",
    "            if isSpam == 0:\n",
    "                wordDict[word.lower()][0] += 1\n",
    "            # index 1: ham\n",
    "            else:\n",
    "                wordDict[word.lower()][1] += 1\n",
    "        else:\n",
    "            # index 0: spam\n",
    "            if isSpam == 0:\n",
    "                wordDict[word.lower()] = [1,0]\n",
    "                # index 1: ham\n",
    "            else:\n",
    "                wordDict[word.lower()] = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in trainDict.keys():\n",
    "    # get relevant information\n",
    "    body = trainDict[k]['payload']\n",
    "    charset = trainDict[k]['charset']\n",
    "    isSpam = trainDict[k]['isSpam']\n",
    "    if charset==None:\n",
    "        charset='ascii'\n",
    "    u = unicode(body, charset)\n",
    "    \n",
    "    # Tokenize using Spacy\n",
    "    try:\n",
    "        words = en_nlp(u)\n",
    "        for word in words:\n",
    "            addToDict(word, isSpam)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Testing for individual email (smaller run time)\n",
    "# k = trainDict.keys()[281]\n",
    "# body = trainDict[k]['payload']\n",
    "# charset = trainDict[k]['charset']\n",
    "# isSpam = trainDict[k]['isSpam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"wordDictData.pickle\", \"w\") as f:\n",
    "    pickle.dump(wordDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"wordDictData.pickle\", \"rb\") as f:\n",
    "    wordDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get descending order of word counts. Index 0: spam, Index 1: ham\n",
    "sorted(wordDict.items(), key= lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix 2: TextBlob <br>\n",
    "Use text blob to classify data since it has methods that allow us to explore why each feature is given a particular weight. For e.g. We can see the top five important features and waht about those features can be enhanced for better results. But it takes insanely long amount of time to train the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spacy english module\n",
    "import spacy\n",
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source: http://wiki.apache.org/spamassassin/BayesStopList\n",
    "# SpamAssasin: word length < 3 excluded and words in given list excluded\n",
    "exclusive_list = ['able', 'all', 'already', 'and', 'any', 'are', 'because','both', 'can', 'come', 'each', 'email', 'even', 'few', 'first', 'for', 'from', 'give', 'has', 'have', 'http', 'information', 'into', \"it's\", 'just', 'know','like', 'long', 'look', 'made', 'mail', 'mailing', 'mailto', 'make', 'many','more', 'most', 'much', 'need', 'not', 'now', 'number', 'off', 'one', 'only', 'out', 'own', 'people', 'place', 'right', 'same', 'see', 'such', 'that', 'the', 'this', 'through', 'time', 'using', 'web', 'where', 'why', 'with', 'without', 'work', 'world', 'year', 'years', 'you', 'your', \"you're\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ignore_word(word):\n",
    "    # ignore digits, punctuation marks, spaces, stop words, new line chars\n",
    "    if word.is_digit or word.is_punct or word.is_space or word.is_stop or str(word)=='\\n' or word.like_num:\n",
    "        return True\n",
    "    elif word in exclusive_list:\n",
    "        return True\n",
    "    elif len(str(word)) < 3:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = list() # list of tuples (email body, isSpam label)\n",
    "\n",
    "for k in trainDict:\n",
    "    # get body\n",
    "    body = trainDict[k]['payload']\n",
    "    charset = trainDict[k]['charset']\n",
    "    isSpam = trainDict[k]['isSpam']\n",
    "    if charset == None:\n",
    "        charset = 'ascii'\n",
    "    u = unicode(body, charset)\n",
    "    try:\n",
    "        # Tokenize using Spacy\n",
    "        words = en_nlp(u)\n",
    "        # Get relevant tokens\n",
    "        relevant_words = ''\n",
    "        for word in words:\n",
    "            if ignore_word(word):\n",
    "                continue\n",
    "            # consider words that contain alphabets or look like urls\n",
    "            elif word.is_alpha or word.like_url:\n",
    "                relevant_words+= str(word) + ' '\n",
    "        # append to list and labels\n",
    "        l.append((relevant_words, isSpam))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test = train_test_split(l, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Warning: make take more than an hour to train\n",
    "cl = NaiveBayesClassifier(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl.accuracy(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show top 5 informative features\n",
    "cl.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix 3: Clean Email Data <br>\n",
    "Payload for each email is decode based on charset and encoded to ascii. <br>\n",
    "This cleansed version is pickled for SpamAssassin API Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = list() # list of tuples (email body, isSpam label)\n",
    "for k in trainDict:\n",
    "    # get body\n",
    "    body = trainDict[k]['payload']\n",
    "    charset = trainDict[k]['charset']\n",
    "    isSpam = trainDict[k]['isSpam']\n",
    "    if charset == None:\n",
    "        charset = 'ascii'\n",
    "    bodyStr = body.decode(charset, errors='replace').encode('utf-8', 'replace')\n",
    "\n",
    "    # append to list and labels\n",
    "    l.append((bodyStr, isSpam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle\n",
    "with open(\"cleanmailData.pickle\", \"w\") as f:\n",
    "    pickle.dump(trainDict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
